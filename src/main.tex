\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[portuguese]{babel}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{pgfplots}
\usepackage{hyperref}
\usepackage{float}
\pgfplotsset{compat=1.4}
\usepgfplotslibrary{statistics}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

    \hypersetup{
    pdfsubject={Estudo de hierarquia de memória},
    pdfcreator={GLR, LSO, THN},
    colorlinks=true,       		% false: boxed links; true: colored links
    linkcolor=black,          	% color of internal links
    citecolor=black,        		% color of links to bibliography
    filecolor=black,      		% color of file links
    urlcolor=black,
    bookmarksdepth=4
}


\begin{document}

\title{Estudo de hierarquia de memória}

\author{\IEEEauthorblockN{1\textsuperscript{st} Gustavo Lopes Rodrigues}
\IEEEauthorblockA{\textit{Instituto de Ciências Exatas e Informática} \\
\textit{Pontifícia Universidade Católica de Minas Gerais (PUC-MG)}\\
Belo Horizonte, Brasil \\
gustavolr@gmail.com}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Homenique Vieira Martins}
\IEEEauthorblockA{\textit{Instituto de Ciências Exatas e Informática} \\
\textit{Pontifícia Universidade Católica de Minas Gerais (PUC-MG)}\\
Belo Horizonte, Brasil \\
Homenique.T@gmail.com}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Lucas Santiago de Oliveira}
\IEEEauthorblockA{\textit{Instituto de Ciências Exatas e Informática} \\
\textit{Pontifícia Universidade Católica de Minas Gerais (PUC-MG)}\\
Belo Horizonte, Brasil \\
lu.santi.oliveira@gmail.com}
\and
\IEEEauthorblockN{4\textsuperscript{th} Thiago Henriques Nogueira}
\IEEEauthorblockA{\textit{Instituto de Ciências Exatas e Informática} \\
\textit{Pontifícia Universidade Católica de Minas Gerais (PUC-MG)}\\
Belo Horizonte, Brasil \\
thiagohnogueira01@gmail.com}
}

\maketitle

\begin{abstract}
   Memória Cache em computadores tem vários algoritmos de 
  substituição de dados, dois desses algoritmos são \emph{FIFO}( First In, First Out )
  e \emph{LRU}( Least Recently Used ), decidimos estudar a eficiência destes dois algoritmos.
  Nossa ideia antecedente é de que o LRU fosse alcançar um desempenho superior ao FIFO, com o 
  aumento do número de instruções e o aumento progressivo da Cache. Foram analisados
  em vários testes com quantidade de instruções diferentes e em hardwares,
  variados visando avaliar como esses algoritmos atuariam em tais situações.
  Desta forma, poderíamos ter uma visão clara de que tanto a modificação
  do hardware quanto das instruções que executam sobre eles têm um impacto significativo
  na eficiência da leitura e escrita de dados da RAM para a cache ou de volta para a memória
  principal.
\end{abstract}

\begin{IEEEkeywords}
Cache, algoritmos, FIFO, LRU, Tamanho Cache
\end{IEEEkeywords}

\section{Introdução}

%Espera-se que nesta seção, seja escrita uma contextualização inicial 
%para situar o leitor. Ou seja, saber em qual área ele está "pisando".
%No contexto discutido, é apresentado um problema em aberto (um problema 
%pode ser escrito como uma pergunta), em seguida um objetivo para "responder" 
%ao problema descrito. Depois, a contribuição científica é descrita, e por fim, 
%um parágrafo para descrever a organização do artigo é feito.

A Cache é um dispositivo de acesso rápido, que fica localizado dentro do processador,
com a intenção de reduzir o acesso do processador à memória principal, que demanda um
tempo de acesso muito superior à cache. Criando uma referência da localidade do dado na 
memória principal, até mesmo gravando esses dados, porém existe um limite de quantos 
dados podem ser armazenados para isso é necessário uma política de armazenamento para 
reocupar espaço quando necessário.

Desde a invenção dos computadores, a busca por otimizar os processos que são executados 
nos hardwares se tornou foco, considerando que simples ajustes podem render grandes 
ganhos de desempenho. Dessa forma, um algoritmo eficiente na leitura e escrita de 
dados na cache é de suma importância. 

Com isso em mente, pensamos em políticas de substituição clássicos, LRU e o FIFO, para
averiguar qual possui melhor desempenho em diferentes cenários. Começamos pensando em 
aumentar gradativamente o número de instruções que acessam as palavras na RAM para serem 
escritas na cache. Dessa forma, seria simples visualizar como o número de instruções
influencia no tempo de acesso aos dados. Além disso, pensamos também em vários cenários 
com caches de diferentes tamanhos, desde de o mínimo de espaço possível até uma cache 
de mesmo tamanho que a memória RAM.

O resto do papel está organizado da seguinte maneira. Seção 2 irá mostrar pesquisas correlatas,
apresentar de maneira breve o assunto de cada e se existe algo que possa contribuir com a pesquisa atual.
Seção 3 apresenta as arquiteturas utilizadas para a realização dos testes, assim também com os cenários 
que foram testados. Resultados experimentais são colocados na Seção 4. Por fim, a Seção 5 dá conclusão 
a nossa pesquisa.

\section{Trabalhos Correlatos}

%Nesta seção, artigos relacionados à simulações de memória são apresentados.
%Por exemplo, para cada artigo, um parágrafo. Ao final, um parágrafo que menciona
%a diferença entre o artigo em questão e os artigos correlatos.

A partir de James E. Smith e James R. Goodman\cite{b1}, tanto algoritmos de LRU quanto de FIFO para
uma cache possuem o pior desempenho possível quando comparados a qualquer outro algoritmo. 
O exemplo principal deles foi mostrar como mapeamento aleatório consegue ser várias vezes mais eficaz, 
uma vez que programas que precisam reescrever muitas vezes a cache e remover um valor que será reutilizado 
em um futuro muito próximo.

Considerando que é um artigo escrito em 1985, muitas coisas mudaram e não podemos usar mais esses resultados
como verdadeiros em situações do dia-a-dia. Tanto o LRU quanto o FIFO se mostram ineficientes quando
os programas se tornam maiores do que o tamanho de toda a cache do processador (resultado apresentado pelo artigo
deles). Hoje, temos caches muito maiores do que naquela época, com isso, o principal foco da pesquisa do Smith e 
do Goodman diminuindo o seu valor nos dias de hoje.Pois eles estavam considerando caches extremamente pequenas, na maior 
parte das vezes inferior ao tamanho de aplicações comuns do cotidiano.

Por outro lado, o artigo \cite{b2}, por ser de 2008 poderia ser mais promissor em apresentar 
dados que ajudariam em nossa pesquisa, porém não foi isso que aconteceu. A pesquisa da Universidade de 
Rennes faz também análise da memória Cache em relação as políticas de substituição. Entretanto, as políticas 
utilizadas(fora a LRU) são diferentes e não há a utilização da FIFO. Além de que, o objetivo da pesquisa é de usar 
dados teóricos para melhorar um método de análise de instrução estática de cache usando Pseudo LRU e a política 
aleatória de troca. E mesmo assim, o próprio artigo provou que métodos não LRU demonstraram uma significante perca de precisão.

\section{Metodologia ou Proposta de Arquiteturas}

%A metodologia utilizada no artigo consiste no estudo de artigos que se correlacionam com o tema estudado, 
%como também a utilização e desenvolvimento de arquiteturas feitas no simulador Amnesia.
  Para a elaboração de teste utilizamos o simulador-Amnésia para elaborar algumas
arquiteturas (tabelas \ref{tab1} e \ref{tab2}) que a partir delas executamos os testes (tabela \ref{tab3})
\begin{table}[H]
  \caption{características gerais da arquitetura i}
    \centering
      \begin{tabular}{|c|c|c|c|}
          \hline
          \textbf{Especificações} & \multicolumn{3}{|c|}{\textbf{Partes da Arquitetura}} \\
          \cline{2-4} 
          \textbf{da Arquitetura} & \textbf{\textit{Processador}}& \textbf{\textit{CPU}}& \textbf{\textit{Trace}} \\
          \hline
          Tamanho da palavra & --- & 4 & 4 \\
          \hline
          processorContains & 0 & --- & --- \\
          \hline
          Ciclos por escrita & 0 & --- & --- \\
          \hline
      \end{tabular}
      \label{tab1}
\end{table}

\begin{table}[H]
  \caption{características gerais da arquitetura ii}
  \centering
      \begin{tabular}{|c|c|c|}
          \hline
          \textbf{Especificações} & \multicolumn{2}{|c|}{\textbf{Partes da Arquitetura}} \\
          \cline{2-3} 
          \textbf{da Arquitetura} & \textbf{\textit{Memória Principal}}& \textbf{\textit{Cache}} \\
          \hline
          Tamanho da linha / bloco & 1 & 1  \\
          \hline
          Ciclos por leitura & 1 & 1  \\
          \hline
          Ciclos por escrita & 2 & 2  \\
          \hline
          Tempo do ciclo & 10 & 1  \\
          \hline
          Tamanho da memória & 16 & {$^{\mathrm{*}}$}2  \\
          \hline
          Associatividade & --- & 2  \\
          \hline
          Politica de escrita & --- & Write-Through  \\
          \hline
          Politica de substituição & --- & {$^{\mathrm{*}}$}FIFO  \\
          \hline
          \multicolumn{3}{l}{$^{\mathrm{*}}$ Os valores com o asterisco foram os valores modificados.}
      \end{tabular}
      \label{tab2}
\end{table}

As tabelas acima mostram a arquitetura inicial utilizada no projeto para o 
desenvolvimento dos diversos cenários que foram originados.    

\begin{table}[H]
  \caption{Dados modificados}
  \centering
      \begin{tabular}{|c|c|c|}
          \hline
          \textbf{Especificações} & \multicolumn{2}{|c|}{\textbf{Valores}} \\
          \cline{2-3} 
          \textbf{da Arquitetura} & \textbf{Tamanho da Memoria} & \textbf{Politica de Substituição} \\
          \hline
          Cenário 1 & 2 & FIFO \\
          \hline
          Cenário 2 & 2 & LRU \\
          \hline
          Cenário 3 & 4 & FIFO\\
          \hline
          Cenário 4 & 4 & LRU\\
          \hline
          Cenário 5 & 8 & FIFO\\
          \hline
          Cenário 6 & 8 & LRU\\
          \hline
          Cenário 7 & 16 & FIFO\\
          \hline
          Cenário 8 & 16 & LRU\\
          \hline
          %\multicolumn{3}{l} {Sample of a Table footnote.}
      \end{tabular}
      \label{tab3}
\end{table}

Ao modificar o valor do tamanho da memória e da política de substituição da cache,
é possível criar 8 cenários distintos para se avaliar o impacto do tamanho da cache
no desempenho dos metodos de substituição. Sendo assim, com os cenários propostos
foram realizados diversos testes com o intuito de analisar a Localidade Temporal e 
Localidade Espacial nas arquiteturas.

\section{Avaliação dos Resultados}

%Nesta seção, os resultados são apresentados em gráficos. Para cada figura,
%importante lembrar que deve ter texto com explicação.
%Caso a metodologia de avaliação não tenha sido descrita em uma seção específica,
%esta pode ser descrita no início desta seção.

Nos gráficos subsequentes, há uma demonstração de como a memória cache se comporta 
ao ser usada com um grande conjunto de instruções de \emph{load} e \emph{store} 
(maior que sua capacidade) em cenários com caches de 2, 4, 8 e 16 linhas.
Para fazer esses testes utilizamos um conjunto de 10, 50, 100, 250, 500, 750, 1.000 e 10.000 
instruções.

\subsection{Gráficos de hit rate por número de instruções}

  \begin{figure}[H]
    \centering
    \caption{\textit{\textbf{Cache com algoritmo de substituição FIFO}}}
  \begin{tikzpicture}

    \begin{axis}[
      width =\linewidth - 21,
      xlabel=Quantidade de instrução,
      ylabel=\textbf{Hit rate},
      domain = 1:10000,
      xmin=10, xmax=10000,
      ymin=0, ymax=1,
      xmode = log,
      log basis x={10},
      clip=false,
      every axis plot/.append style={thick},
      ymajorgrids=true,
      legend  style={at={(0.5 ,-0.20)},
      anchor=north,legend  columns =-1},
    ]
    \addplot [mark=*] coordinates {
      (10, 0.1)
      (50, 0.12)
      (100, 0.12)
      (250, 0.168)
      (500, 0.196)
      (750, 0.19733334)
      (1000, 0.207)
      (10000, 0.1947)
    };
    \addplot [mark=triangle] coordinates {
      (10, 0.2)
      (50, 0.22)
      (100, 0.28)
      (250, 0.356)
      (500, 0.374)
      (750, 0.36666667)
      (1000, 0.381)
      (10000, 0.3913)
   };
   \addplot [mark=square] coordinates {
      (10, 0.3)
      (50, 0.6)
      (100, 0.71)
      (250, 0.788)
      (500, 0.782)
      (750, 0.7733333)
      (1000, 0.786)
      (10000, 0.7983)
   };
   \addplot [solid] coordinates {
      (10, 0.3)
      (50, 0.8)
      (100, 0.9)
      (250, 0.96)
      (500, 0.98)
      (750, 0.9866667)
      (1000, 0.99)
      (10000, 0.999)
   };

  \legend{2 linhas, 4 linhas, 8 linhas, 16 linhas}

    \end{axis}
    
  \end{tikzpicture}

\end{figure}

  \begin{figure}[H]
    \caption{\textit{\textbf{Cache com algoritmo de substituição LRU}}}
  \begin{tikzpicture}

    \begin{axis}[
      width =\linewidth - 21,
      xlabel=Quantidade de instrução,
      ylabel=\textbf{Hit rate},
      domain = 1:10000,
      xmin=10, xmax=10000,
      ymin=0, ymax=1,
      xmode = log,
      log basis x={10},
      clip=false,
      every axis plot/.append style={thick},
      ymajorgrids=true,
      legend  style={at={(0.5 ,-0.20)},
      anchor=north,legend  columns =-1},
    ]
    \addplot [mark=*] coordinates {
      (10, 0.1)
      (50, 0.14)
      (100, 0.13)
      (250, 0.172)
      (500, 0.194)
      (750, 0.19733334)
      (1000, 0.205)
      (10000, 0.1945)
    };
    \addplot [mark=triangle] coordinates {
      (10, 0.2)
      (50, 0.26)
      (100, 0.3)
      (250, 0.368)
      (500, 0.374)
      (750, 0.364)
      (1000, 0.383)
      (10000, 0.3928)
   };
   \addplot [mark=square] coordinates {
      (10, 0.3)
      (50, 0.58)
      (100, 0.7)
      (250, 0.788)
      (500, 0.784)
      (750, 0.77066666)
      (1000, 0.788)
      (10000, 0.7961)
   };
   \addplot [solid] coordinates {
      (10, 0.3)
      (50, 0.8)
      (100, 0.9)
      (250, 0.96)
      (500, 0.98)
      (750, 0.9866667)
      (1000, 0.99)
      (10000, 0.999)
   };

  \legend{2 linhas, 4 linhas, 8 linhas, 16 linhas}

    \end{axis}
    
  \end{tikzpicture}

\end{figure}

Os dois gráficos mostrados foram montados usando os valores que extraímos. Nota-se que os resultados foram muito próximos, aos resultados de James E. Smith
e James R. Goodman\cite{b1}. Considerando que no início, pensávamos que haveria uma diferença significativa entre os algoritmos LRU e FIFO para substituição
de valores na cache, achamos que nossos testes estavam errados e que precisaríamos refazê-los, ao ler o artigo vimos que os nossos resultados na verdade estavam
bem dentro do esperado.
	
Nossos testes apenas foram feitos usando caches completamente associativos, pensamos em fazer com a associatividade por conjunto e direta, mas depois de resultados
tão inesperados, pensamos em pesquisar outros artigos relacionados que já tivessem feito esses testes para comparar os resultados e ver se os resultados seriam
diferentes. Ao ver os dados do artigo\cite{b1}, descobrimos que teríamos valores bem semelhantes dentro dessas três arquiteturas. 

Para colocar em perspectiva nossos resultados, os dados em \cite{b2} foram 
medidos usando benchmarks mantido pelos grupos de pesquisa, considerando uma
cache de 2KB com 32 bytes de linhas. Eles são expressos em termos da porcentagem de 
hits na cache detectada pela análise feita pelo grupo. A política de LRU se demonstrou 
mais eficiente do que a PLRU e a política aleatória de troca, em apenas alguns casos que 
não houve diferença entre as análises, porém na pesquisa d \cite{b2} foi utilizado também 
como parâmetro o tempo de vída mínimo de um elemento na cache(\emph{Minimum life span)})

\subsection{Tempo total de acesso aos dados por quantidade de instruções}

\raggedbottom

\begin{figure}[H]

  \caption{\textit{\textbf{Tempo total de acesso aos dados com algoritmo FIFO}}}
  \begin{tikzpicture}

    \begin{axis}[
      width =\linewidth - 21,
      xlabel=Quantidade de instrução,
      ylabel=\textbf{Tempo de acesso à Cache},
      domain = 1:10000,
      xmin=10, xmax=10000,
      ymin=1, ymax=100000,
      ymode = log,
      log basis y={10},
      xmode = log,
      log basis x={10},
      clip=false,
      every axis plot/.append style={thick},
      ymajorgrids=true,
      legend  style={at={(0.5 ,-0.20)},
      anchor=north,legend  columns =-1},
    ]
    \addplot [mark=*] coordinates {
      (10, 100)
      (50, 490)
      (100, 980)
      (250, 2330)
      (500, 4520)
      (750, 6770)
      (1000, 8930)
      (10000, 90530)
    };
    \addplot [mark=triangle] coordinates {
      (10, 90)
      (50, 440)
      (100, 820)
      (250, 1860)
      (500, 3630)
      (750, 5500)
      (1000, 7190)
      (10000, 70870)
   };
   \addplot [mark=square] coordinates {
      (10, 80)
      (50, 250)
      (100, 390)
      (250, 780)
      (500, 1590)
      (750, 2450)
      (1000, 3140)
      (10000, 30170)
   };
   \addplot [solid] coordinates {
      (10, 80)
      (50, 150)
      (100, 200)
      (250, 350)
      (500, 600)
      (750, 850)
      (1000, 1100)
      (10000, 10100)
   };

  \legend{2 linhas, 4 linhas, 8 linhas, 16 linhas}

    \end{axis}
    
  \end{tikzpicture}

\end{figure}

  \begin{figure}[H]


  \caption{\textit{\textbf{Tempo total de acesso aos dados com algoritmo LRU}}}

  \begin{tikzpicture}

    \begin{axis}[
      width =\linewidth - 21,
      xlabel=Quantidade de instrução,
      ylabel=\textbf{Tempo de acesso a Cache},
      domain = 1:10000,
      xmin=10, xmax=10000,
      ymin=1, ymax=100000,
      ymode = log,
      log basis y={10},
      xmode = log,
      log basis x={10},
      clip=false,
      every axis plot/.append style={thick},
      ymajorgrids=true,
      legend  style={at={(0.5 ,-0.20)},
      anchor=north,legend  columns =-1},
    ]
    \addplot [mark=*] coordinates {
      (10, 100)
      (50, 480)
      (100, 970)
      (250, 2320)
      (500, 4530)
      (750, 6770)
      (1000, 8950)
      (10000, 90550)
    };
    \addplot [mark=square] coordinates {
      (10, 90)
      (50, 420)
      (100, 800)
      (250, 1830)
      (500, 3630)
      (750, 5520)
      (1000, 7170)
      (10000, 70720)
   };
   \addplot [mark=triangle] coordinates {
      (10, 80)
      (50, 260)
      (100, 400)
      (250, 780)
      (500, 1580)
      (750, 2470)
      (1000, 3120)
      (10000, 30390)
   };
   \addplot [solid] coordinates {
      (10, 80)
      (50, 150)
      (100, 200)
      (250, 350)
      (500, 600)
      (750, 850)
      (1000, 1100)
      (10000, 10100)
   };

  \legend{2 linhas, 4 linhas, 8 linhas, 16 linhas}

    \end{axis}
    
  \end{tikzpicture}

\end{figure}

Esses dois últimos gráficos, seguindo a mesma linha do hit rate, mantêm proximidade dos valores no tempo de acesso dos dados,
desde copiar da RAM para a cache até acessar esse valor no processador. Dentro dos valores que experimentamos, os valores se 
mantiveram bem próximos. O tempo de acesso aos dados se mostrou fora do padrão apenas no caso da cache com 16 linhas (mesmo tamanho que o processador) 
houve uma grande queda no tempo de acesso dos dados. Em todos os outros casos, o tempo se manteve muito próximo, mesmo que entre caches de 2 a 8 linhas de tamanho.

Esses dadas nos mostram que para ter algum ganho significativo de performance seria necessário ter uma cache de tamanho próximo ao da RAM. 
Seria algo completamente impraticável considerando a diferença de preço por unidade de memória entre as duas. O cache se apresenta com 
gasto de tempo bastante próximos quando em tamanhos usados em processadores comerciais. Demonstrando que independente desses algoritmos 
possuem um maior hit hate em caches maiores. Dessa forma, aumentar a cache importa mais do que o algoritmo escolhido.


\section{Conclusões}

%Nas conclusões, inicia-se com um breve resumo do que foi o trabalho desenvolvido,
%depois faz-se uma discussão acerca dos objetivos alcançados. Ou seja, os objetivos
%apresentados na Introdução casam com os resultados discutidos na seção de Resultados? 
%Quais resultados podem ser destacados? Por fim, há um parágrafo para apresentar possíveis trabalhos futuros.

Após a realização dos testes em todos os cenários propostos, e uma análise dos gráficos apresentados, houve um 
receio de que o ponto da pesquisa não havia sido alcançado, já que os resultados se mostraram pouco expressivos. 
Em nosso caso, tanto o LFU quanto o FIFO tiveram um desempenho com diferença menor que 5\% entre eles, em alguns 
casos nem havendo diferença alguma. Porém, após uma análise e estudo dos artigos correlacionados, foi possível observar que 
a política de substituição LRU se mostra de forma pouco significativa mais eficiente do que a política FIFO. 

Tudo que descobrimos esteve desde Smith e Goodman \cite{b1} que disseram que não há diferença de desempenho entre os algoritmos 
e que aleatoriedade é mais eficiente. Enquanto no artigo da Samira Mirbagher Ajorpaz, Elba Garza, Sangam Jindal, e Daniel A. Jiménez\cite{b3}, 
mostrou que o desempenho do LRU é pouco superior ao FIFO, algo que consegue ser detectado, mas seu uso diário não teria melhora perceptível e 
que seria mais importante considerar outros tantos algoritmos que possuem um desempenho significativamente superior aos dois anteriores. Por fim, 
o artigo de Aurore Junier, Damien Hardy, Isabelle Puaut \cite{b2}, mostrou algo inusitado, indo na direção oposta dos outros dois artigos, 
apresentou dados de que o LRU possui sim um desempenho superior à inserção aleatória de dados na cache.

Concluindo, nossos testes demonstraram que não há grande diferença desses algoritmos quando usados em caches pequenas, os dois primeiros artigos
concordam com nosso posicionamento, enquanto o outro artigo discordou. Dessa forma, é importante manter essa discussão aberta para novos experimentos.
Considerando que cenários de testes diferentes apresentam resultados completamente dispersos.

\begin{thebibliography}{00}
\bibitem{b1} J. Smith and B. Goodman, ''Instruction Cache Replacement Policies and Organizations'' in \emph{IEEE Transactions on Computers}, vol. C-34, no.3, pp. 234--241, March 1985.
\bibitem{b2} A. Junier, D. Hardy and I. Puaut, ''Impact of instruction cache replacement policy on the tightness of WCET estimation'', in \emph{IRISA}, University of Rennes, [Documento online] , 2008. Disponível em: ReserchGate, \url{https://www.researchgate.net/publication/239761570_Impact_of_instruction_cache_replacement_policy_on_the_tightness_of_WCET_estimation} [Acessado em: 14 de Abril de 2021] 
\bibitem{b3} S. Ajorpaz, E. Garza, S. Jindal and D. Jiménez, ''Exploring Predictive Replacement Policies for Instruction Cache and Branch Target Buffer,'' in \emph{ACM/IEEE 45th Annual International Symposium on Computer Architecture (ISCA)}, Los Angeles, CA, USA, 2018, pp. 519-532
\end{thebibliography}

\end{document}